services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    volumes:
      - ollama:/root/.ollama
    ports:
      - "11434:11434"
    restart: unless-stopped

  mcp_server:
      build: 
        context: .
        dockerfile: Dockerfile
      container_name: mcp_server
      ports:
        - "8000:8000"
      volumes:
        - ./src:/app
        - /var/run/docker.sock:/var/run/docker.sock
      environment:
        - PYTHONUNBUFFERED=1
      command: python mcp_server.py

  agent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: agent
    working_dir: /app
    volumes:
      - ./src:/app
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_HOST=http://ollama:11434
    depends_on:
      - ollama
      - mcp_server

    command: python main.py

    ## Debug Config
    # ports:
    #   - "5678:5678"  # The default port for debugpy
    # # This command starts the debugger and waits for you to attach VS Code
    # command: python -m debugpy --listen 0.0.0.0:5678 --wait-for-client main.py
    

volumes:
  ollama:
  external:
    name: ollama