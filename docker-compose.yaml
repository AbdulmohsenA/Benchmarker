services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    volumes:
      - ollama:/root/.ollama
    ports:
      - "11434:11434"
    restart: unless-stopped

  dashboard:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: dashboard
    ports:
      - "8501:8501"
    volumes:
      - ./src:/app
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_HOST=http://ollama:11434
      - MCP_SERVER_URL=http://mcp_server:8000/sse
    depends_on:
      - ollama
      - mcp_server
    command: streamlit run main.py --server.address=0.0.0.0

  mcp_server:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mcp_server
    ports:
      - "8000:8000"
    volumes:
      - ./src:/app
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - PYTHONUNBUFFERED=1
    command: python mcp_server.py

  mcp_server-debug:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mcp_server
    ports:
      - "8000:8000"
      - "5679:5679"
    volumes:
      - ./src:/app
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - PYTHONUNBUFFERED=1
    command: python -m debugpy --listen 0.0.0.0:5679 --wait-for-client mcp_server.py
    profiles: ["debug"]

  agent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: agent
    working_dir: /app
    volumes:
      - ./src:/app
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_HOST=http://ollama:11434
    depends_on:
      - ollama
      - mcp_server
    command: python agent.py 1

  agent-debug:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: agent
    working_dir: /app
    ports:
      - "5678:5678"
    volumes:
      - ./src:/app
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_HOST=http://ollama:11434
    depends_on:
      - ollama
      - mcp_server-debug
    command: python -m debugpy --listen 0.0.0.0:5678 --wait-for-client agent.py 0
    profiles: ["debug"]

volumes:
  ollama:
    external:
      name: ollama